initializer: [he, xavier, uniform]
eta: [0.001, 0.0001, 0.00001]
alpha: [0.5, 0.7, 0.9]
lambd: [0.001, 0.0001, 0.00001]
units: [
          [64, 3],
          [64, 64, 3],
          [256, 3],
          [256, 256, 3],
          [512, 3],
          [512, 512, 3],
          [1024, 3],
          [1024, 1024, 3],
]
activations: [
          ['relu', 'identity'],
          ['relu', 'relu', 'identity']
]